# 詳細設計書

## 1. 概要

本プログラムは、非線形な関数（サインカーブ）にノイズを加えたデータセットを用いて、決定木回帰モデルの深さ（max_depth）を変化させた場合のバイアス・バリアンスの挙動を視覚的に確認し、定量的に評価することを目的としています。

具体的には、以下の処理を行います。

- サイン関数にノイズを加えたデータセットの生成
- データセットのトレーニングセットとテストセットへの分割
- 決定木回帰モデルの深さを変えながら、ブートストラップサンプリングによる複数モデルの学習とテストデータへの予測
- 予測結果の可視化（複数モデルの予測線群と真値の比較）
- バイアス・バリアンスの計算とプロットによる評価

---

## 2. 使用ライブラリ

| ライブラリ名            | 用途                                         |
|-------------------------|----------------------------------------------|
| numpy                   | 数値計算、乱数生成、配列操作                   |
| matplotlib.pyplot       | グラフ描画                                   |
| sklearn.tree.DecisionTreeRegressor | 決定木回帰モデルの構築と学習                   |
| sklearn.metrics.mean_squared_error | （本コードでは未使用）誤差計算用                 |
| sklearn.model_selection.train_test_split | データセットの分割                             |
| sklearn.utils.resample  | ブートストラップサンプリング                   |

---

## 3. 処理詳細

### 3.1 データセット生成

- 乱数シードを固定（`np.random.seed(42)`）し、再現性を確保しています。
- 入力変数 `X` は一様分布 `[-3, 3]` から1000個のサンプルを生成し、縦ベクトル（1000行1列）に整形しています。
- 目的変数 `y` は `sin(X)` に正規分布ノイズ（平均0、標準偏差0.1または0.2）を加えたものです。
- 真の関数値 `y_eq` はノイズなしの `sin(X)` の値を保持しています。

### 3.2 データ分割

- `train_test_split` を用いて、データをトレーニングセット（70%）とテストセット（30%）に分割しています。
- 真の関数値 `y_eq` も同様に分割し、後のバイアス計算に利用します。
- テストデータは、可視化のために入力値 `X_test` の昇順にソートし、それに合わせて `y_test` と `y_eq_test` もソートしています。

### 3.3 モデル学習と予測

- 決定木回帰モデルの深さ `max_depth` を1から15（または1から4）まで変化させて評価します。
- 各深さに対して、以下の処理を300回（`B=300`）繰り返します。
  - トレーニングセットからブートストラップサンプリング（復元抽出）を行い、新たな学習データを作成します。
  - 決定木回帰モデルを作成し、サンプリングしたデータで学習します。
  - 学習済みモデルを用いて、ソート済みのテストデータに対する予測値を計算し、リストに保存します。

### 3.4 予測結果の可視化

- 各深さごとに300個のモデルの予測曲線をグレーの薄い線で描画し、予測のばらつきを視覚化します。
- 真の関数値（ノイズなしの `sin(X)`）を赤色の線で描画します。
- 実際のテストデータの観測値（ノイズあり）を赤い点でプロットします。
- グラフにはタイトル、軸ラベル、凡例、グリッドを設定し、見やすくしています。

### 3.5 バイアス・バリアンスの計算

- 各深さごとに300個の予測値を配列に変換し、形状は `(B, テストデータ数)` となります。
- バイアスの二乗（Bias^2）は、各テストデータ点における平均予測値と真の関数値の差の二乗の平均として計算します。
- バリアンス（Variance）は、各テストデータ点における300個の予測値の分散の平均として計算します。
- 計算したバイアス二乗とバリアンスをリストに格納します。

### 3.6 バイアス・バリアンスのプロット

- 深さごとのバイアス二乗とバリアンスを折れ線グラフで描画します。
- 青色の丸印でバイアス二乗、緑色のバツ印でバリアンスを示し、深さに伴う誤差の変化を視覚的に把握できます。
- グラフにはタイトル、軸ラベル、凡例、グリッドを設定しています。

---

## 4. 変数一覧

| 変数名               | 型・形状           | 説明                                   |
|----------------------|--------------------|--------------------------------------|
| `X`                  | ndarray (1000,1)   | 入力データ（説明変数）                 |
| `y`                  | ndarray (1000,)    | 目的変数（ノイズあり）                 |
| `y_eq`               | ndarray (1000,)    | 真の関数値（ノイズなし）               |
| `X_train`, `X_test`  | ndarray            | トレーニング・テスト用の入力データ     |
| `y_train`, `y_test`  | ndarray            | トレーニング・テスト用の目的変数       |
| `y_eq_train`, `y_eq_test` | ndarray        | トレーニング・テスト用の真の関数値     |
| `sort_idx`           | ndarray            | テストデータソート用のインデックス     |
| `X_test_sorted`      | ndarray            | ソート済みテスト入力データ             |
| `y_test_sorted`      | ndarray            | ソート済みテスト目的変数               |
| `y_eq_test_sorted`   | ndarray            | ソート済みテスト真の関数値             |
| `max_depths`         | ndarray            | 決定木の深さの範囲                     |
| `B`                  | int                | ブートストラップサンプル数（300）      |
| `predictions_test`   | list / ndarray     | 各モデルのテストデータに対する予測値   |
| `bias_squared`       | list               | 深さごとのバイアス二乗値               |
| `variance`           | list               | 深さごとのバリアンス値                 |

---

## 5. 処理の流れ（概要）

1. データ生成・分割
2. テストデータのソート
3. 決定木の深さを変えながら以下を繰り返す
   - ブートストラップサンプリングによる学習データ作成
   - 決定木モデルの学習
   - テストデータに対する予測値の取得
   - 予測値の可視化
   - バイアス・バリアンスの計算
4. バイアス・バリアンスの深さ依存性をプロット

---

## 6. 注意事項

- ブートストラップサンプリングにより、各モデルは異なる学習データセットで学習されるため、予測値にばらつきが生じます。
- 決定木の深さが浅い場合はモデルが単純すぎてバイアスが大きくなり、深い場合は過学習によりバリアンスが大きくなる傾向があります。
- ノイズの大きさやサンプル数、ブートストラップ回数は適宜調整可能です。
- グラフ表示はJupyter Notebook等のインタラクティブ環境での利用を想定しています。

---

## 7. まとめ

本プログラムは、決定木回帰モデルの複数の深さに対して、ブートストラップサンプリングを用いたアンサンブル的な予測を行い、その結果からバイアス・バリアンスのトレードオフを視覚的かつ定量的に評価することができます。これにより、モデルの複雑さが予測性能に与える影響を理解しやすくなっています。