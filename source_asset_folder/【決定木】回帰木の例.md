```python
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import datetime
import yfinance as yf

#ターゲットを指定
ticker = "4755.T"

#データを収集
data = yf.download(ticker , period='1y', interval = "1d")
```

    [*********************100%%**********************]  1 of 1 completed
    


```python
data
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Open</th>
      <th>High</th>
      <th>Low</th>
      <th>Close</th>
      <th>Adj Close</th>
      <th>Volume</th>
    </tr>
    <tr>
      <th>Date</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2023-06-14</th>
      <td>555.500000</td>
      <td>556.000000</td>
      <td>545.500000</td>
      <td>547.400024</td>
      <td>547.400024</td>
      <td>22274800</td>
    </tr>
    <tr>
      <th>2023-06-15</th>
      <td>542.000000</td>
      <td>543.000000</td>
      <td>518.500000</td>
      <td>518.500000</td>
      <td>518.500000</td>
      <td>50921900</td>
    </tr>
    <tr>
      <th>2023-06-16</th>
      <td>520.000000</td>
      <td>522.500000</td>
      <td>510.000000</td>
      <td>515.700012</td>
      <td>515.700012</td>
      <td>43554600</td>
    </tr>
    <tr>
      <th>2023-06-19</th>
      <td>517.700012</td>
      <td>518.700012</td>
      <td>506.000000</td>
      <td>514.200012</td>
      <td>514.200012</td>
      <td>31783900</td>
    </tr>
    <tr>
      <th>2023-06-20</th>
      <td>509.000000</td>
      <td>510.700012</td>
      <td>493.500000</td>
      <td>502.100006</td>
      <td>502.100006</td>
      <td>49013500</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2024-06-10</th>
      <td>848.000000</td>
      <td>849.700012</td>
      <td>827.000000</td>
      <td>839.000000</td>
      <td>839.000000</td>
      <td>20148400</td>
    </tr>
    <tr>
      <th>2024-06-11</th>
      <td>840.200012</td>
      <td>842.799988</td>
      <td>812.599976</td>
      <td>818.900024</td>
      <td>818.900024</td>
      <td>20501000</td>
    </tr>
    <tr>
      <th>2024-06-12</th>
      <td>815.799988</td>
      <td>818.500000</td>
      <td>803.099976</td>
      <td>808.700012</td>
      <td>808.700012</td>
      <td>15514800</td>
    </tr>
    <tr>
      <th>2024-06-13</th>
      <td>813.500000</td>
      <td>813.500000</td>
      <td>802.099976</td>
      <td>802.700012</td>
      <td>802.700012</td>
      <td>12672200</td>
    </tr>
    <tr>
      <th>2024-06-14</th>
      <td>799.099976</td>
      <td>815.400024</td>
      <td>799.000000</td>
      <td>813.599976</td>
      <td>813.599976</td>
      <td>12234400</td>
    </tr>
  </tbody>
</table>
<p>247 rows × 6 columns</p>
</div>




```python
# 日経スクレイピング　　https://protogram.jp/lesson/python-selenium-beautifulsoup-2
# 日経スクレイピング　　https://qiita.com/sho_cullni/items/2935e2f18a6b4049db38

import requests
from bs4 import BeautifulSoup
import pandas as pd

# Webスクレイピングに必要なリスト作成
elements_title = []
elements_url = []

# Webスクレイピング処理
def get_nikkei_news():
    url = "https://www.nikkei.com/"
    response = requests.get(url)
    html = response.text
    soup = BeautifulSoup(html, "html.parser")

    # titleとurlについての処理
    articles = soup.find_all('a', class_='k-card__title-link')  # セレクタの確認

    for article in articles:
        title = article.get_text(strip=True)
        link = article.get('href')
        if link and title:
            elements_title.append(title)
            if not link.startswith("http"):
                link = "https://www.nikkei.com" + link
            elements_url.append(link)

# Webスクレイピング処理呼び出し
get_nikkei_news()

# pandas処理
df = pd.DataFrame({"news_title": elements_title, "news_url": elements_url})
print(df)


# import requests
# from bs4 import BeautifulSoup
# import pandas as pd

# # Webスクレイピングに必要なリスト作成
# elements_title = []
# elements_url = []

# # Webスクレイピング処理
# def get_nikkei_news():
#     url = "https://www.nikkei.com/"
#     response = requests.get(url)
#     html = response.text
#     soup = BeautifulSoup(html, "html.parser")

#     # titleとurlについての処理
#     articles = soup.find_all('a', class_='k-card__block-link')

#     for article in articles:
#         title = article.get_text(strip=True)
#         link = article.get('href')
#         if link and title:
#             elements_title.append(title)
#             if not link.startswith("http"):
#                 link = "https://www.nikkei.com" + link
#             elements_url.append(link)

# # Webスクレイピング処理呼び出し
# get_nikkei_news()

# # pandas処理
# df = pd.DataFrame({"news_title": elements_title, "news_url": elements_url})
# print(df)


# import requests
# from bs4 import BeautifulSoup
# import pandas as pd

# #Webスクレイピングに必要なリスト作成
# elements_title = []
# elements_url = []

# #Webスクレイピング処理
# def get_nikkei_news():
#     url = "https://www.nikkei.com/"
#     response = requests.get(url)
#     html = response.text
#     soup = BeautifulSoup(html,"html.parser")

#     #titleについての処理
#     title_list = soup.select(".k-card__block-link")
#     for title in title_list:
#         elements_title.append(title.text)

#     #urlについての処理
#     url_list = soup.select(".k-card__block-link")
#     for i in url_list:
#         urls = i.get("href")
#         if "http" not in urls:
#             urls = "https://www.nikkei.com" + urls
#             elements_url.append(urls)
#         else:
#             elements_url.append(urls)

# #Webスクレイピング処理呼び出し
# get_nikkei_news()

# #pandas処理
# df = pd.DataFrame({"news_title":elements_title,
#                    "news_url":elements_url})
# print(df)
# # df.to_csv("nikkei_test_select.csv", index=False, encoding="utf-8")


```

    Empty DataFrame
    Columns: [news_title, news_url]
    Index: []
    


```python
result
```


    ---------------------------------------------------------------------------

    NameError                                 Traceback (most recent call last)

    Cell In[21], line 1
    ----> 1 result
    

    NameError: name 'result' is not defined



```python
import pandas as pd
import numpy as np

np.random.seed(0)
n = 1000

# 特徴量 X1 の生成 (層化のためのカテゴリ変数)
X1 = np.random.choice(['A', 'B'], size=n, p=[0.5, 0.5])

# 特徴量 X2 の生成
X2_A = np.random.normal(10, 5, size=n//2)
X2_B = np.random.normal(20, 5, size=n//2)

X2 = np.concatenate([X2_A, X2_B])

# 目的変数 Y の生成
Y_A = 2 * X2_A + np.random.normal(0, 5, size=n//2)
Y_B = -1 * X2_B + np.random.normal(0, 5, size=n//2)

Y = np.concatenate([Y_A, Y_B])

data = pd.DataFrame({'X1': X1, 'X2': X2, 'Y': Y})

```


```python
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import train_test_split

X = data[['X1', 'X2']]
X = pd.get_dummies(X, drop_first=True)  # カテゴリ変数のエンコーディング
Y = data['Y']

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)

model = DecisionTreeRegressor(random_state=0)
model.fit(X_train, Y_train)

Y_pred = model.predict(X_test)

```


```python
import matplotlib.pyplot as plt
import seaborn as sns

# 全体の X2 と Y の関係
plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
sns.scatterplot(x='X2', y='Y', data=data)
plt.title('Without Stratification')

# X1 による層化後の X2 と Y の関係
plt.subplot(1, 2, 2)
sns.scatterplot(x='X2', y='Y', hue='X1', data=data)
plt.title('With Stratification by X1')

plt.show()

```


    
![png](output_6_0.png)
    



```python
import pandas as pd
import numpy as np
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import seaborn as sns

# データ生成
np.random.seed(0)
n = 5000

# 年齢層の生成 (0: 若年層, 1: 高齢層)
age = np.random.choice([0, 1], size=n, p=[0.6, 0.4])

# 予防接種の生成 (0: 受けない, 1: 受ける)
vaccinated = np.random.choice([0, 1], size=n, p=[0.5, 0.5])

# 各グループのサイズを計算
young_not_vaccinated_size = ((age == 0) & (vaccinated == 0)).sum()
young_vaccinated_size = ((age == 0) & (vaccinated == 1)).sum()
old_not_vaccinated_size = ((age == 1) & (vaccinated == 0)).sum()
old_vaccinated_size = ((age == 1) & (vaccinated == 1)).sum()

# 重症化の生成
young_not_vaccinated = np.random.binomial(1, 0.3, size=young_not_vaccinated_size)
young_vaccinated = np.random.binomial(1, 0.1, size=young_vaccinated_size)
old_not_vaccinated = np.random.binomial(1, 0.6, size=old_not_vaccinated_size)
old_vaccinated = np.random.binomial(1, 0.5, size=old_vaccinated_size)

severity = np.zeros(n)
severity[(age == 0) & (vaccinated == 0)] = young_not_vaccinated
severity[(age == 0) & (vaccinated == 1)] = young_vaccinated
severity[(age == 1) & (vaccinated == 0)] = old_not_vaccinated
severity[(age == 1) & (vaccinated == 1)] = old_vaccinated

# DataFrame にまとめる
data = pd.DataFrame({'age': age, 'vaccinated': vaccinated, 'severity': severity})

# 回帰木モデルの作成
X = data[['age', 'vaccinated']]
Y = data['severity']

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)

model = DecisionTreeClassifier(random_state=0)
model.fit(X_train, Y_train)

Y_pred = model.predict(X_test)

# 可視化
plt.figure(figsize=(14, 6))

# 全体の vaccinated と severity の関係
plt.subplot(1, 2, 1)
sns.barplot(x='vaccinated', y='severity', data=data, ci=None)
plt.title('Without Stratification')

# age による層化後の vaccinated と severity の関係
plt.subplot(1, 2, 2)
sns.barplot(x='vaccinated', y='severity', hue='age', data=data, ci=None)
plt.title('With Stratification by Age')

plt.show()

```

    C:\Users\tamta\AppData\Local\Temp\ipykernel_35616\2529185193.py:55: FutureWarning: 
    
    The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.
    
      sns.barplot(x='vaccinated', y='severity', data=data, ci=None)
    C:\Users\tamta\AppData\Local\Temp\ipykernel_35616\2529185193.py:60: FutureWarning: 
    
    The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.
    
      sns.barplot(x='vaccinated', y='severity', hue='age', data=data, ci=None)
    


    ---------------------------------------------------------------------------

    AttributeError                            Traceback (most recent call last)

    Cell In[10], line 60
         58 # age による層化後の vaccinated と severity の関係
         59 plt.subplot(1, 2, 2)
    ---> 60 sns.barplot(x='vaccinated', y='severity', hue='age', data=data, ci=None)
         61 plt.title('With Stratification by Age')
         63 plt.show()
    

    File c:\anaconda3\Lib\site-packages\seaborn\categorical.py:2763, in barplot(data, x, y, hue, order, hue_order, estimator, errorbar, n_boot, units, seed, orient, color, palette, saturation, width, errcolor, errwidth, capsize, dodge, ci, ax, **kwargs)
       2760 if ax is None:
       2761     ax = plt.gca()
    -> 2763 plotter.plot(ax, kwargs)
       2764 return ax
    

    File c:\anaconda3\Lib\site-packages\seaborn\categorical.py:1587, in _BarPlotter.plot(self, ax, bar_kws)
       1585 """Make the plot."""
       1586 self.draw_bars(ax, bar_kws)
    -> 1587 self.annotate_axes(ax)
       1588 if self.orient == "h":
       1589     ax.invert_yaxis()
    

    File c:\anaconda3\Lib\site-packages\seaborn\categorical.py:767, in _CategoricalPlotter.annotate_axes(self, ax)
        764     ax.set_ylim(-.5, len(self.plot_data) - .5, auto=None)
        766 if self.hue_names is not None:
    --> 767     ax.legend(loc="best", title=self.hue_title)
    

    File c:\anaconda3\Lib\site-packages\matplotlib\axes\_axes.py:322, in Axes.legend(self, *args, **kwargs)
        204 @_docstring.dedent_interpd
        205 def legend(self, *args, **kwargs):
        206     """
        207     Place a legend on the Axes.
        208 
       (...)
        320     .. plot:: gallery/text_labels_and_annotations/legend.py
        321     """
    --> 322     handles, labels, kwargs = mlegend._parse_legend_args([self], *args, **kwargs)
        323     self.legend_ = mlegend.Legend(self, handles, labels, **kwargs)
        324     self.legend_._remove_method = self._remove_legend
    

    File c:\anaconda3\Lib\site-packages\matplotlib\legend.py:1361, in _parse_legend_args(axs, handles, labels, *args, **kwargs)
       1357     handles = [handle for handle, label
       1358                in zip(_get_legend_handles(axs, handlers), labels)]
       1360 elif len(args) == 0:  # 0 args: automatically detect labels and handles.
    -> 1361     handles, labels = _get_legend_handles_labels(axs, handlers)
       1362     if not handles:
       1363         log.warning(
       1364             "No artists with labels found to put in legend.  Note that "
       1365             "artists whose label start with an underscore are ignored "
       1366             "when legend() is called with no argument.")
    

    File c:\anaconda3\Lib\site-packages\matplotlib\legend.py:1291, in _get_legend_handles_labels(axs, legend_handler_map)
       1289 for handle in _get_legend_handles(axs, legend_handler_map):
       1290     label = handle.get_label()
    -> 1291     if label and not label.startswith('_'):
       1292         handles.append(handle)
       1293         labels.append(label)
    

    AttributeError: 'numpy.int32' object has no attribute 'startswith'



    
![png](output_7_2.png)
    

