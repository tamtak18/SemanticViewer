```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn import tree
import matplotlib.pyplot as plt

# データの読み込み
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data"
column_names = [
    "age", "sex", "cp", "trestbps", "chol", "fbs", "restecg", "thalach", "exang", 
    "oldpeak", "slope", "ca", "thal", "target"
]
data = pd.read_csv(url, names=column_names)

# '?'をNaNに置き換え
data.replace('?', pd.NA, inplace=True)

# 欠損値を含む行を削除
data.dropna(inplace=True)

# データの前処理
X = data.drop('target', axis=1)
y = data['target']

# データ型を適切に変換
X = X.astype(float)
y = y.astype(int)

# トレーニングセットとテストセットに分割
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 決定木モデルの構築
model = DecisionTreeClassifier(max_depth=7, random_state=42)
model.fit(X_train, y_train)

# モデルの予測
y_pred = model.predict(X_test)

# モデルの評価
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# クラス名を動的に取得
class_names = [str(cls) for cls in model.classes_]

# 決定木の可視化
plt.figure(figsize=(20,10))
tree.plot_tree(model, feature_names=X.columns.tolist(), class_names=class_names, filled=True)
plt.show()
```

    Confusion Matrix:
     [[28  6  2  0  0]
     [ 3  3  2  1  0]
     [ 1  1  1  2  0]
     [ 0  6  1  0  0]
     [ 0  0  3  0  0]]
    
    Classification Report:
                   precision    recall  f1-score   support
    
               0       0.88      0.78      0.82        36
               1       0.19      0.33      0.24         9
               2       0.11      0.20      0.14         5
               3       0.00      0.00      0.00         7
               4       0.00      0.00      0.00         3
    
        accuracy                           0.53        60
       macro avg       0.23      0.26      0.24        60
    weighted avg       0.56      0.53      0.54        60
    
    

    c:\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
      _warn_prf(average, modifier, msg_start, len(result))
    c:\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
      _warn_prf(average, modifier, msg_start, len(result))
    c:\anaconda3\Lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
      _warn_prf(average, modifier, msg_start, len(result))
    


    
![png](output_0_2.png)
    



```python
data.head(100)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>sex</th>
      <th>cp</th>
      <th>trestbps</th>
      <th>chol</th>
      <th>fbs</th>
      <th>restecg</th>
      <th>thalach</th>
      <th>exang</th>
      <th>oldpeak</th>
      <th>slope</th>
      <th>ca</th>
      <th>thal</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>63.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>145.0</td>
      <td>233.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>150.0</td>
      <td>0.0</td>
      <td>2.3</td>
      <td>3.0</td>
      <td>0.0</td>
      <td>6.0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>67.0</td>
      <td>1.0</td>
      <td>4.0</td>
      <td>160.0</td>
      <td>286.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>108.0</td>
      <td>1.0</td>
      <td>1.5</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>67.0</td>
      <td>1.0</td>
      <td>4.0</td>
      <td>120.0</td>
      <td>229.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>129.0</td>
      <td>1.0</td>
      <td>2.6</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>7.0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>37.0</td>
      <td>1.0</td>
      <td>3.0</td>
      <td>130.0</td>
      <td>250.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>187.0</td>
      <td>0.0</td>
      <td>3.5</td>
      <td>3.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>41.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>130.0</td>
      <td>204.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>172.0</td>
      <td>0.0</td>
      <td>1.4</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>96</th>
      <td>59.0</td>
      <td>1.0</td>
      <td>4.0</td>
      <td>110.0</td>
      <td>239.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>142.0</td>
      <td>1.0</td>
      <td>1.2</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>7.0</td>
      <td>2</td>
    </tr>
    <tr>
      <th>97</th>
      <td>60.0</td>
      <td>0.0</td>
      <td>4.0</td>
      <td>150.0</td>
      <td>258.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>157.0</td>
      <td>0.0</td>
      <td>2.6</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>7.0</td>
      <td>3</td>
    </tr>
    <tr>
      <th>98</th>
      <td>52.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>134.0</td>
      <td>201.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>158.0</td>
      <td>0.0</td>
      <td>0.8</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>3.0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>99</th>
      <td>48.0</td>
      <td>1.0</td>
      <td>4.0</td>
      <td>122.0</td>
      <td>222.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>186.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>100</th>
      <td>45.0</td>
      <td>1.0</td>
      <td>4.0</td>
      <td>115.0</td>
      <td>260.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>185.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>3.0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>100 rows × 14 columns</p>
</div>


