```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
from sklearn.utils import resample

# 非線形なデータセットを生成 (サインカーブに少量のノイズを加えたもの)
np.random.seed(42)
X = np.random.uniform(-3, 3, 1000).reshape(-1, 1)
y = np.sin(X).ravel() + np.random.normal(0, 0.1, X.shape[0])  # ノイズを減らす

# データをトレーニングセットとテストセットに分割
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# テストデータをソート
sort_idx = np.argsort(X_test.ravel())
X_test_sorted = X_test[sort_idx]
y_test_sorted = y_test[sort_idx]

# 決定木の深さを様々に変えてバイアス・バリアンスを計算
max_depths = np.arange(1, 16)  # 1から15までの深さ
B = 300  # ブートストラップサンプルの数

for max_depth in max_depths:
    predictions_test = []  # テストセットの予測値をリストで管理
    
    # ブートストラップサンプリングとモデルの構築
    for b in range(B):
        # ブートストラップサンプリング
        X_train_bootstrap, y_train_bootstrap = resample(X_train, y_train)
        
        # 決定木モデルの作成と学習
        model = DecisionTreeRegressor(max_depth=max_depth, random_state=b)
        model.fit(X_train_bootstrap, y_train_bootstrap)
        
        # テストデータに対する予測を記録（ソートされたテストデータに基づく予測）
        predictions_test.append(model.predict(X_test_sorted))
    
    # predictions_test を配列に変換 (B, len(y_test)) の形にする
    predictions_test = np.array(predictions_test)

    # 折れ線群と真値のプロット（真値は点群で表示）
    plt.figure(figsize=(10, 6))
    for b in range(B):
        plt.plot(X_test_sorted, predictions_test[b], color='gray', alpha=0.1)  # 各モデルの予測値をプロット
    plt.scatter(X_test_sorted, y_test_sorted, color='red', label='True Values', s=10)  # 真値を点群でプロット
    plt.title(f'Predictions vs True Values at Depth = {max_depth}')
    plt.xlabel('X')
    plt.ylabel('y')
    plt.legend()
    plt.grid(True)
    plt.show()

    # バイアス・バリアンスの確認を行うため、深さごとの折れ線群と真値の違いを視覚的に確認します。

```


    
![png](output_0_0.png)
    



    
![png](output_0_1.png)
    



    
![png](output_0_2.png)
    



    
![png](output_0_3.png)
    



    
![png](output_0_4.png)
    



    
![png](output_0_5.png)
    



    
![png](output_0_6.png)
    



    
![png](output_0_7.png)
    



    
![png](output_0_8.png)
    



    
![png](output_0_9.png)
    



    
![png](output_0_10.png)
    



    
![png](output_0_11.png)
    



    
![png](output_0_12.png)
    



    
![png](output_0_13.png)
    



    
![png](output_0_14.png)
    



```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import train_test_split
from sklearn.utils import resample

# 非線形なデータセットを生成 (サインカーブに少量のノイズを加えたもの)
np.random.seed(42)
X = np.random.uniform(-3, 3, 1000).reshape(-1, 1)
y = np.sin(X).ravel() + np.random.normal(0, 0.2, X.shape[0])  # ノイズを減らす
y_eq = np.sin(X).ravel()
# データをトレーニングセットとテストセットに分割
X_train, X_test, y_train, y_test, y_eq_train, y_eq_test = train_test_split(X, y, y_eq, test_size=0.3, random_state=42)

# テストデータをソート
sort_idx = np.argsort(X_test.ravel())
X_test_sorted = X_test[sort_idx]
y_test_sorted = y_test[sort_idx]
y_eq_test_sorted = y_eq_test[sort_idx]

# 決定木の深さを様々に変えてバイアス・バリアンスを計算
max_depths = np.arange(1, 5)  # 1から15までの深さ
B = 300  # ブートストラップサンプルの数
bias_squared = []
variance = []

for max_depth in max_depths:
    predictions_test = []  # テストセットの予測値をリストで管理
    
    # ブートストラップサンプリングとモデルの構築
    for b in range(B):
        # ブートストラップサンプリング
        X_train_bootstrap, y_train_bootstrap = resample(X_train, y_train)
        
        # 決定木モデルの作成と学習
        model = DecisionTreeRegressor(max_depth=max_depth, random_state=b)
        model.fit(X_train_bootstrap, y_train_bootstrap)
        
        # テストデータに対する予測を記録（ソートされたテストデータに基づく予測）
        predictions_test.append(model.predict(X_test_sorted))
    
    # 折れ線群と真値のプロット（真値は点群で表示）
    plt.figure(figsize=(10, 6))
    for b in range(B):
        plt.plot(X_test_sorted, predictions_test[b], color='gray', alpha=0.1)  # 各モデルの予測値をプロット
    plt.plot(X_test_sorted, y_eq_test_sorted, color='red')  # 各モデルの予測値をプロット
    plt.scatter(X_test_sorted, y_test_sorted, color='red', label='True Values', s=10)  # 真値を点群でプロット
    plt.title(f'Predictions vs True Values at Depth = {max_depth}')
    plt.xlabel('X')
    plt.ylabel('y')
    plt.legend()
    plt.grid(True)
    plt.show()
    
    # predictions_test を配列に変換 (B, len(y_test)) の形にする
    predictions_test = np.array(predictions_test)
    
    # バイアスの計算: 平均予測値と実際の値との差の二乗を計算し、その平均を取る
    avg_predictions_test = np.mean(predictions_test, axis=0)
    bias_squared.append(np.mean((avg_predictions_test - y_eq_test_sorted) ** 2))
    
    # バリアンスの計算: 各データ点に対する予測値の分散を計算し、その平均を取る
    variance.append(np.mean(np.var(predictions_test, axis=0)))

# バイアスとバリアンスをプロット
plt.figure(figsize=(10, 6))
plt.plot(max_depths, bias_squared, label='Bias^2', color='blue', marker='o')
plt.plot(max_depths, variance, label='Variance', color='green', marker='x')
plt.title('Bias and Variance vs Tree Depth')
plt.xlabel('Tree Depth')
plt.ylabel('Error')
plt.legend()
plt.grid(True)
plt.show()

```


    
![png](output_1_0.png)
    



    
![png](output_1_1.png)
    



    
![png](output_1_2.png)
    



    
![png](output_1_3.png)
    



    
![png](output_1_4.png)
    

